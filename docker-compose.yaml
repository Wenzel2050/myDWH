version: '3.8'
services:
  postgres:
    image: postgres:16
    expose:
      - 5432
    env_file:
      - path: dwh.env
        required: true
    volumes:
      - ./data/db_data:/var/lib/postgresql/data
      - ./docker/postgres/docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  redis:
    image: redis:7.2-bookworm
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always

  airflow-webserver:
    image: apache/airflow:2.9.3
    command: webserver
    env_file:
      - path: dwh.env
        required: true
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      dwh-init:
        condition: service_completed_successfully
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./data/sources/dags:/opt/airflow/dags
      - ./data/logs/airflow:/opt/airflow/logs
      - ./data/config/airflow:/opt/airflow/config
      - ./data/addons/airflow:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock

  airflow-scheduler:
    image: apache/airflow:2.9.3
    command: scheduler
    env_file:
      - path: dwh.env
        required: true
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      dwh-init:
        condition: service_completed_successfully
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./data/sources/dags:/opt/airflow/dags
      - ./data/logs/airflow:/opt/airflow/logs
      - ./data/config/airflow:/opt/airflow/config
      - ./data/addons/airflow:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock

  airflow-worker:
    image: apache/airflow:2.9.3
    command: celery worker
    env_file:
      - path: dwh.env
        required: true
    environment:
      DUMB_INIT_SETSID: "0"
    healthcheck:
      test: 
        - "CMD-SHELL"
        - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      dwh-init:
        condition: service_completed_successfully
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./data/sources/dags:/opt/airflow/dags
      - ./data/logs/airflow:/opt/airflow/logs
      - ./data/config/airflow:/opt/airflow/config
      - ./data/addons/airflow:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock

  airflow-triggerer:
    image: apache/airflow:2.9.3
    command: triggerer
    env_file:
      - path: dwh.env
        required: true
    environment:
      DUMB_INIT_SETSID: "0"
    healthcheck:
      test: 
        - "CMD-SHELL"
        - 'airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      dwh-init:
        condition: service_completed_successfully
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./data/sources/dags:/opt/airflow/dags
      - ./data/logs/airflow:/opt/airflow/logs
      - ./data/config/airflow:/opt/airflow/config
      - ./data/addons/airflow:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock

  git-sync:
    image: toda-gitsync
    environment:
      GIT_SYNC_BRANCH: 'main'
      GIT_SYNC_REPO: ''
      GIT_SYNC_FORCE_ACCEPT_SSH_HOST_KEY: ''
      GIT_SYNC_FORCE_ACCEPT_SSH_PORT_KEY: ''

    volumes:
      - /root/.ssh/id_rsa

  dwh-init:
    image: apache/airflow:2.9.3
    entrypoint: /bin/bash
    env_file:
      - path: dwh.env
        required: true
    command:
      - -c
      - |
        mkdir -p /opt/sources/{dags,hop,dbt} /opt/addons/{airflow,hop,dbt} /opt/logs/{airflow,hop,dbt}
        chown -R "${AIRFLOW_UID:-50000}:0" /opt/sources /opt/addons /opt/logs
        exec /entrypoint airflow version
        sleep 6000
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./data/sources:/opt/sources
      - ./data/logs:/opt/logs
      - ./data/addons:/opt/addons
